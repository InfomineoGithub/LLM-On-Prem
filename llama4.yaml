envs:
  HF_TOKEN: null

resources:
  image_id: docker:lmsysorg/sglang:latest
  accelerators: A100:2
  ports: 30000

run: |
  conda deactivate
  python3 -m sglang.launch_server \
    --model-path meta-llama/Llama-4-Scout-17B-16E-Instruct \
    --tp 2 \
    --context-length 65536 \
    --host 0.0.0.0 \
    --port 30000 \
    --trust-remote-code \
    --chat-template llama-4 \
    --attention-backend fa3